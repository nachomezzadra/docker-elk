input {
	tcp {
		type => "dss"
		port => 5000
	}
}

## Add your filters here

filter {

	if [type] == "dss" {
		  grok {
			   #Node Transition at 2015-10-29T16:39:03Z for UCID: 00002003761446157930, ANI: 55053, Call Flow Key: 54725, Call Flow Name: A Call Flow that changed its name just to see how it is reported in EP, MPP Session ID: RHEL6464AAEP7-2015302154144-19, UUI: , Sequence Number: 1, Source Node: init, Source Node Type: initial, Link Code: defaultLanguage, Target Node: decision, Target Node Type: decision, Call Center Service: .
			   match => [ "message", "%{TIMESTAMP_ISO8601:logTimestamp} %{PROG:timeZone} %{DATA:httpThread} INFO  CALL_LOGGER_FILE  - Node Transition at %{DATA:logTimestampString} for UCID: %{WORD:UCID}, ANI: %{WORD:ANI}, Call Flow Key: %{WORD:callFlowKey}, Call Flow Name: %{DATA:callFlowName}, MPP Session ID: %{DATA:mppSessionID}, UUI: %{DATA:uui}, Sequence Number: %{INT:sequenceNumber}, Source Node: %{DATA:souceNode}, Source Node Type: %{DATA:sourceNodeType}, Link Code: %{DATA:linkCode}, Target Node: %{DATA:targetNode}, Target Node Type: %{DATA:targetNodeType}, Call Center Service: %{DATA:callCenterService}"]

			   match => [ "ANI", "^(\+? ?(?!9?\d{0}))?(\(?0?(?<areaCode>\d{3})\)? ?)" ]

         add_field => {
                  "transitionName" => "%{souceNode}__%{linkCode}__%{targetNode}"
          }

			   break_on_match => false
		  }

		  grok {
			  #New Call Started at 2015-10-29T16:56:34Z with the following details.  UCID: 00002004231446158983, ANI: 55053, Call Flow Key: 54725, Call Flow Name: A Call Flow that changed its name just to see how it is reported in EP, MPP Session ID: 57F36B274A38B0D37F0C3B9A1FA9E5D4:/dss-flow-app, UUI: .
    		match => ["message", "New Call Started at %{TIMESTAMP_ISO8601:logTimestampString} with the following details.  UCID: %{WORD:UCID}, ANI: %{WORD:ANI}, Call Flow Key: %{WORD:callFlowKey}, Call Flow Name: %{DATA:callFlowName}, MPP Session ID: %{DATA:mppSessionID}, UUI: %{DATA:uui}"]
    		add_tag => [ "callStarted" ]
  		}

		  grok {
			  #Call Ended at 2015-10-29T16:56:37Z with the following details.  UCID: 00002004231446158983, ANI: 55053, Call Flow Key: 54725, Call Flow Name: A Call Flow that changed its name just to see how it is reported in EP, MPP Session ID: RHEL6464AAEP7-2015302155916-7, UUI: , Transferred to:
    		match => ["message", "Call Ended at %{TIMESTAMP_ISO8601:logTimestampString} with the following details.  UCID: %{WORD:UCID}, ANI: %{WORD:ANI}, Call Flow Key: %{WORD:callFlowKey}, Call Flow Name: %{DATA:callFlowName}, MPP Session ID: %{DATA:mppSessionID}, UUI: %{DATA:uui}, Transferred to: %{GREEDYDATA:transferredTo}"]
    		add_tag => [ "callEnded" ]
  		}  		


       # The timestamp may have commas instead of dots. Convert so as to store everything in the same way
        mutate {
            gsub => [
                # replace all dashes with dots
                "logTimestampString", "T", ";"
                ]
        }        

        mutate {
            gsub => [
                "logTimestampString", ":", "."
                ]
        }

        mutate {
            gsub => [
                "logTimestampString", "Z", ""
                ]
        }      


        date {
            match => ["logTimestampString", "YYYY-MM-dd;HH.mm.ss", "YYYY-MM-dd;HH:mm:ss", "MMM dd YYY HH:mm:ss", "MMM  d YYY HH:mm:ss", "ISO8601"]
            target => "@timestamp"
        }


	  	elapsed {
		    start_tag => "callStarted"
		    end_tag => "callEnded"
		    unique_id_field => "UCID"
		    timeout => 180
		    new_event_on_match => false
	  	}

      geoareacode {
        source => "areaCode"
        target => "coordinates"
        database => "/etc/logstash/conf.d/extras/logstash/filters/data/GeoIPCity-534-Location-US.csv"
        add_field => [ "[geoareacode][coordinates]", "%{[coordinates][longitude]}" ]
        add_field => [ "[geoareacode][coordinates]", "%{[coordinates][latitude]}"  ]
        add_field => [ "[geoareacode][longitude]", "%{[coordinates][longitude]}" ]
        add_field => [ "[geoareacode][latitude]", "%{[coordinates][latitude]}"  ]        
        add_field => [ "[longitude]", "%{[coordinates][longitude]}" ]
        add_field => [ "[latitude]", "%{[coordinates][latitude]}"  ]        
      }

      mutate {
        convert => [ "[geoareacode][latitude]", "float"]
        convert => [ "[geoareacode][longitude]", "float"]
        convert => [ "[geoareacode][coordinates]", "float"]
      }
  }
}


output {
  	elasticsearch { 
  		  #index => "dss-%{+YYYY.MM.dd}"
        hosts => "192.168.99.100:9200"
        # template => "etc/logstash/conf.d/dss-template.yaml"

  	}

   # stdout {
   #      codec => rubydebug      
   #  }	
}
